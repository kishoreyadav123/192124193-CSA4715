class SigmoidActivation:
    def forward(self, inputs):
        self.inputs = inputs
        return 1 / (1 + np.exp(-inputs))
    
    def backward(self, dvalues):
        sigmoid = 1 / (1 + np.exp(-self.inputs))
        return dvalues * sigmoid * (1 - sigmoid)

nn_sigmoid = NeuralNetwork()

nn_sigmoid.add_layer(DenseLayer(2, 4))
nn_sigmoid.add_layer(SigmoidActivation())
nn_sigmoid.add_layer(DenseLayer(4, 1))

x = np.array([[0.1, 0.2]])

output_sigmoid = nn_sigmoid.forward(x)
print("Output with Sigmoid Activation:", output_sigmoid)

dummy_gradients = np.array([[0.1]])
dvalues_sigmoid = nn_sigmoid.backward(dummy_gradients)
print("Gradients after backward pass with Sigmoid Activation:", dvalues_sigmoid)